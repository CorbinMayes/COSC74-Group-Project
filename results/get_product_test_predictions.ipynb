{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../libraries/\")\n",
    "from selector import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes list of text fields (e.g. summary or reviewText fields) and\n",
    "# tokenizes, removes stop words and stems. Returns result as array of \n",
    "# lists, one list per review\n",
    "def preprocess_data(doc_set):    \n",
    "    # initialize regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # create English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in doc_set:\n",
    "        if not i:\n",
    "            i = ' '\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        tokens.append('null__') # add a bias term, will work as a kind of prior, important for empty reviews\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "# takes an array of lists as input, product labels, uniq_labels, and ratings,\n",
    "# and merges lists with matching labels among labels uniq_labels, averages\n",
    "# reviews belonging to the same, returns merged lists, and averaged ratings\n",
    "# uniq_labels should typically be np.unique(product labels), however \n",
    "# the option of specifying a subset is useful for parallelization to allow\n",
    "# different subsets to be processed by different engines\n",
    "def combine_reviews(text, asins):\n",
    "        products = [asins[0]]\n",
    "        combined_text = [text[0]]\n",
    "\n",
    "        #combine all the summaries into a single text and avg the review ratings for each product\n",
    "        for i in range(1, len(asins)):\n",
    "            last_element_index = len(products) - 1\n",
    "            if(asins[i] == products[last_element_index]):\n",
    "                combined_text[last_element_index] = combined_text[last_element_index] + text[i]\n",
    "                \n",
    "            else:\n",
    "                products.append(asins[i])\n",
    "                combined_text.append(text[i])\n",
    "        \n",
    "        return (combined_text, products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('logisticRegression.clf', mode='rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import and prepare test data\n",
    "with open('../data/Sports_and_Outdoors_Reviews_test.json', 'r') as fp:\n",
    "    json_dat = [json.loads(x) for x in fp.readlines()]\n",
    "\n",
    "#json_dat = json_dat\n",
    "json_dat = sorted(json_dat, key=lambda k: k['asin'])\n",
    "    \n",
    "doc_list = []\n",
    "asin = []\n",
    "test_reviewer_id = []\n",
    "test_unixreviewtime = []\n",
    "for i in range(0,len(json_dat)):\n",
    "    doc_list.append(json_dat[i].get('summary'))\n",
    "    asin.append(json_dat[i].get('asin'))\n",
    "    test_reviewer_id.append(json_dat[i].get('reviewerID'))\n",
    "    test_unixreviewtime.append(json_dat[i].get('unixReviewTime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes ~96 CPU minutes\n",
    "\n",
    "# this cell runs things in parallel. make sure to start an \n",
    "# ipython cluster from the notebook dashboard's IPython Cluster\n",
    "# tab before running\n",
    "import ipyparallel as ipp\n",
    "\n",
    "rc = ipp.Client()\n",
    "dview = rc[:]\n",
    "dview.execute('from nltk.tokenize import RegexpTokenizer;' +\n",
    "              'from nltk.corpus import stopwords; ' + \n",
    "              'from nltk.stem.porter import PorterStemmer;' +\n",
    "              'import numpy as np;')\n",
    "\n",
    "\n",
    "# clean text\n",
    "dview.push(dict(preprocess_data=preprocess_data))\n",
    "dview.scatter('doc_list', doc_list) # partitions data\n",
    "\n",
    "%px cleaned_reviews = preprocess_data(doc_list)\n",
    "cleaned_reviews = dview.gather('cleaned_reviews').get()\n",
    "\n",
    "# combine text\n",
    "total_text, uniq_prod_id = combine_reviews(cleaned_reviews, asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model predictions for test data\n",
    "pred_lbls = clf.predict(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.column_stack((uniq_prod_id, pred_lbls.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Sports_and_Outdoors_Ratings_test.csv\", dat, delimiter=\",\", fmt=['%s', '%s'], \n",
    "           header='asin,awesomeReview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True  True  True False False  True]\n",
      "['002230FD1C13F1EE3B7A487E6C505B67' '00228A1FECFB78004B66CF6559E3E979'\n",
      " '0023FE6BED9B69EB14ECC494FA3F88BF' '00244A1D92CA0B9D9C5C846C96C36E5E'\n",
      " '002EB10683D96CCC7A27DC7D1190C772' '0030C44CE7D39FB47268DFFB1D0A9514'\n",
      " '0032EA58744E6633A5E822DC6BD23E4B' '003E7AFEE9A641B36151F4B1E09F8B5F'\n",
      " '00402D5DB3A9832918645CB72A130E8D']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['00204B63156848D7B5AE05AC221D3B6F', 'Excelente'],\n",
       "       ['00204B63156848D7B5AE05AC221D3B6F', 'Very good basic gloves'],\n",
       "       ['00204B63156848D7B5AE05AC221D3B6F', 'Two Stars'],\n",
       "       ['00204B63156848D7B5AE05AC221D3B6F', 'excelent'],\n",
       "       ['00204B63156848D7B5AE05AC221D3B6F', 'Interesting...'],\n",
       "       ['00204B63156848D7B5AE05AC221D3B6F', 'Great feel'],\n",
       "       ['002230FD1C13F1EE3B7A487E6C505B67',\n",
       "        \"5 *'s on ease of use and effective pain relief!\"],\n",
       "       ['002230FD1C13F1EE3B7A487E6C505B67', \"It's so convenient\"],\n",
       "       ['002230FD1C13F1EE3B7A487E6C505B67', 'Five Stars'],\n",
       "       ['002230FD1C13F1EE3B7A487E6C505B67', 'Perfect'],\n",
       "       ['002230FD1C13F1EE3B7A487E6C505B67', 'Five Stars'],\n",
       "       ['002230FD1C13F1EE3B7A487E6C505B67', 'Three Stars'],\n",
       "       ['00228A1FECFB78004B66CF6559E3E979',\n",
       "        'Love this case for my Verizon white iPhone 4'],\n",
       "       ['00228A1FECFB78004B66CF6559E3E979', 'Perfect Fit'],\n",
       "       ['00228A1FECFB78004B66CF6559E3E979', 'Perfect'],\n",
       "       ['00228A1FECFB78004B66CF6559E3E979', 'Darker but love it!'],\n",
       "       ['00228A1FECFB78004B66CF6559E3E979', 'Five Stars'],\n",
       "       ['00228A1FECFB78004B66CF6559E3E979', 'It is OK'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'Excellent product'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'great'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF',\n",
       "        'Practical mirror for most bikes'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF',\n",
       "        'Mirror is the perfect size to see vehicle coming up on you without ...'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'One Star'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'Five Stars'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'Two Stars'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF',\n",
       "        \"Works surprisingly well, I'm a believer!\"],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF',\n",
       "        'Too small, convex surface distorts'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF',\n",
       "        'but I still like the convex mirror view'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'Yuch'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'Biking safety'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF',\n",
       "        'Works, but could be more functional'],\n",
       "       ['0023FE6BED9B69EB14ECC494FA3F88BF', 'Four Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Grandson Likes It'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Five Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Three Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Great For Helmets!'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Love it for Hockey!'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'These are great for use'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Five Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Five Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Four Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Perfect'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E', 'Five Stars'],\n",
       "       ['00244A1D92CA0B9D9C5C846C96C36E5E',\n",
       "        'Best option for dinking during activity or while wearing a helmet.'],\n",
       "       ['002EB10683D96CCC7A27DC7D1190C772', 'Love it!'],\n",
       "       ['002EB10683D96CCC7A27DC7D1190C772', 'Very nice bottle.'],\n",
       "       ['002EB10683D96CCC7A27DC7D1190C772',\n",
       "        'Excellent Product: Takeeya Water Bottle'],\n",
       "       ['002EB10683D96CCC7A27DC7D1190C772', 'Nice Quality but Fragile.'],\n",
       "       ['002EB10683D96CCC7A27DC7D1190C772', 'Nice Bottles'],\n",
       "       ['0030C44CE7D39FB47268DFFB1D0A9514',\n",
       "        'Just what I was looking for.']], dtype='<U70')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred_lbls[11:20])\n",
    "uniq_asin = np.unique(asin)\n",
    "print(uniq_asin[11:20])\n",
    "np.transpose(np.vstack([asin[350:400], doc_list[350:400]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
