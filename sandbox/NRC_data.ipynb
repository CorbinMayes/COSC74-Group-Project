{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from spellchecker import SpellChecker\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../libraries/\")\n",
    "from selector import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNRC(filename):\n",
    "    \"\"\" Reads the NRC lexicon into a dictionary.\n",
    "    \"\"\"\n",
    "    wordToEmotions = dict()\n",
    "    p_stemmer = PorterStemmer()\n",
    "    count = 0\n",
    "    with open(filename, 'r') as fp:\n",
    "        # Loop through lines\n",
    "        for line in fp.readlines():\n",
    "            line = line.strip('\\n')\n",
    "            words = line.split('\\t')\n",
    "            if len(words) != 3:\n",
    "                continue\n",
    "            # Stem word\n",
    "            word = p_stemmer.stem(words[0])\n",
    "            val = int(line[-1:])\n",
    "            # Store the emotions associated with the word\n",
    "            if count == 0:\n",
    "                wordToEmotions[word] = np.array([val])\n",
    "            else:\n",
    "                wordToEmotions[word] = np.append(wordToEmotions[word],val)\n",
    "                \n",
    "            count = (count + 1)%10\n",
    "    return wordToEmotions\n",
    "\n",
    "lexicon = readNRC(\"../data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\")\n",
    "emotionList = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anger', 1),\n",
       " ('anticipation', 0),\n",
       " ('disgust', 0),\n",
       " ('fear', 0),\n",
       " ('joy', 0),\n",
       " ('negative', 1),\n",
       " ('positive', 0),\n",
       " ('sadness', 0),\n",
       " ('surprise', 0),\n",
       " ('trust', 0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(emotionList, lexicon['hate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dat, val_dat = split_data('../data/Sports_and_Outdoors_Reviews_training.json', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleData = json_dat[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = []\n",
    "for i in sorted(range(len(sampleData)), reverse=True):\n",
    "    if sampleData[i].get('summary').lower().find('star') > 0.0:\n",
    "        sampleData.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.  0.  0.  0.2 0.1 0.1 0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "sp = SpellChecker()\n",
    "\n",
    "# Returns a list with percentage of words which conveyed [anger, anticipation, ... , trust]\n",
    "def getEmotions(words, lexicon):\n",
    "    emotionCount = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "    emotionWords = 0\n",
    "    for word in words:\n",
    "#         print(f'{word}\\r', end='')\n",
    "        # Stem each word\n",
    "        word = p_stemmer.stem(sp.correction(word))\n",
    "        # Sum the emotions\n",
    "        if word in lexicon.keys():\n",
    "            emotionWords += 1\n",
    "            emotionCount = emotionCount + lexicon[word]\n",
    "        \n",
    "    emotionCount[emotionCount == 0] = 0.1\n",
    "    # Avg over all words\n",
    "    if emotionWords > 0:\n",
    "        emotionCount = emotionCount / emotionWords\n",
    "    \n",
    "    return emotionCount\n",
    "\n",
    "string1 = sampleData[45].get('reviewText')\n",
    "print(getEmotions(simple_preprocess(string1, deacc = True), lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have both a Baltimore Ravens and now a Baltimore Orioles lanyard. I use mine for work to hold my ID card. While most just use the standard rope, I like to support my teams any way I can and look cool at it. The lanyard is a good size for an ID badge holder and very well made. The print on it is very sharp and clear. I would recommend this if you are a die hard Orioles fan that works in an office - it is just really cool to show off.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('anger', 0.06896551724137931),\n",
       " ('anticipation', 0.0),\n",
       " ('disgust', 0.034482758620689655),\n",
       " ('fear', 0.06896551724137931),\n",
       " ('joy', 0.034482758620689655),\n",
       " ('negative', 0.10344827586206896),\n",
       " ('positive', 0.27586206896551724),\n",
       " ('sadness', 0.06896551724137931),\n",
       " ('surprise', 0.0),\n",
       " ('trust', 0.13793103448275862)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = i+1\n",
    "string1 = sampleData[i].get('reviewText')\n",
    "em_vec = getEmotions(simple_preprocess(string1, deacc = True), lexicon)\n",
    "print(string1)\n",
    "list(zip(emotionList, em_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes 0.0033037662506103516,Takes 0.0007808208465576172,Takes 0.0003094673156738281,Takes 0.0062711238861083984,Takes 0.000583648681640625,Takes 0.00033926963806152344,Takes 0.0011785030364990234,Takes 0.0018792152404785156,Takes 0.0017588138580322266,Takes 0.4016759395599365,Takes 0.00020933151245117188,Takes 0.0007688999176025391,Takes 0.0011649131774902344,Takes 0.0007798671722412109,Takes 0.0001735687255859375,Takes 0.0012097358703613281,Takes 0.0009903907775878906,Takes 0.0014233589172363281,Takes 0.0008344650268554688,Takes 0.0012199878692626953,Takes 0.0008778572082519531,Takes 0.00012731552124023438,Takes 0.00012350082397460938,Takes 4.352596044540405,Takes 0.6008195877075195,Takes 0.0008301734924316406,Takes 0.00012969970703125,Takes 0.0012807846069335938,Takes 0.0010068416595458984,Takes 1.3344709873199463,"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(30):\n",
    "    ra = randint(0, len(sampleData))\n",
    "    time0 = time.time()\n",
    "    getEmotions(simple_preprocess(sampleData[ra].get('reviewText')), lexicon)\n",
    "    time1 = time.time()\n",
    "    print(f'Takes {time1-time0},',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%]\r"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "emotions = []\n",
    "for i in range(len(sampleData)):\n",
    "    currJson = sampleData[i]\n",
    "    if(not currJson.get('reviewText')):\n",
    "        continue\n",
    "    # Get score\n",
    "    scores.append(currJson.get('overall'))\n",
    "    # Get summary words and do analysis\n",
    "    words, pos = simple_preprocess(currJson.get('reviewText'), deacc=True)\n",
    "    currEmotions = getEmotions(words, lexicon)\n",
    "    emotions.append(currEmotions)\n",
    "    \n",
    "    print('[%d%%]\\r' % (100*(i+1)/len(sampleData)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lbls = np.array(scores) >= 4.5\n",
    "np_emotions = np.array(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "pred_score = cross_val_score(clf, np_emotions, train_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6825   , 0.68875  , 0.685    , 0.68625  , 0.6795995])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45586396599149787"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(emotionList, [np.sum(np_emotions[:,i] > 0)/len(train_lbls) for i in range(0,10)]))\n",
    "np.sum((np_emotions[:,6]>=0.4) == train_lbls)/len(train_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Make the classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6639579947493437\n",
      "Precision: 0.687624183934147\n",
      "Recall: 0.9086646661665416\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
