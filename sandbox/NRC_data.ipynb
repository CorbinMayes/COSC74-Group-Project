{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from spellchecker import SpellChecker\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../libraries/\")\n",
    "from selector import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the NRC lexicon into a dictionary\n",
    "def readNRC(filename):\n",
    "    \"\"\" Reads the NRC lexicon into a dictionary.\n",
    "    \"\"\"\n",
    "    wordToEmotions = dict()\n",
    "    p_stemmer = PorterStemmer()\n",
    "    count = 0\n",
    "    with open(filename, 'r') as fp:\n",
    "        # Loop through lines\n",
    "        for line in fp.readlines():\n",
    "            line = line.strip('\\n')\n",
    "            words = line.split('\\t')\n",
    "            if len(words) != 3:\n",
    "                continue\n",
    "            # Stem word\n",
    "            word = p_stemmer.stem(words[0])\n",
    "#             word = words[0]\n",
    "            val = int(line[-1:])\n",
    "            # Store the emotions associated with the word\n",
    "            if count == 0:\n",
    "                wordToEmotions[word] = np.array([val])\n",
    "            else:\n",
    "                wordToEmotions[word] = np.append(wordToEmotions[word],val)\n",
    "                \n",
    "            count = (count + 1)%10\n",
    "    return wordToEmotions\n",
    "\n",
    "lexicon = readNRC(\"../data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\")\n",
    "emotionList = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 10,
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[('anger', 1),\n",
=======
       "[('anger', 0),\n",
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
       " ('anticipation', 0),\n",
       " ('disgust', 0),\n",
       " ('fear', 0),\n",
       " ('joy', 0),\n",
<<<<<<< HEAD
       " ('negative', 1),\n",
=======
       " ('negative', 0),\n",
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
       " ('positive', 0),\n",
       " ('sadness', 0),\n",
       " ('surprise', 0),\n",
       " ('trust', 0)]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 45,
=======
     "execution_count": 10,
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "list(zip(emotionList, lexicon['hate']))"
=======
    "# Test code\n",
    "p_stemmer = PorterStemmer()\n",
    "list(zip(emotionList, lexicon[p_stemmer.stem('amazement')]))"
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "json_dat, val_dat = split_data('../data/Sports_and_Outdoors_Reviews_training.json', 80)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleData = json_dat[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = []\n",
    "for i in sorted(range(len(sampleData)), reverse=True):\n",
    "    if sampleData[i].get('summary').lower().find('star') > 0.0:\n",
    "        sampleData.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.  0.  0.  0.  0.2 0.1 0.1 0.  0. ]\n"
     ]
    }
   ],
   "source": [
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
    "p_stemmer = PorterStemmer()\n",
    "sp = SpellChecker()\n",
    "\n",
    "# Returns a list with percentage of words which conveyed [anger, anticipation, ... , trust]\n",
    "def getEmotions(text, lexicon):\n",
    "    emotionCount = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "    emotionWords = 0\n",
    "    for word in simple_preprocess(text,deacc=True):\n",
    "        # Stem each word\n",
    "        word = p_stemmer.stem(word)\n",
    "        # Sum the emotions\n",
    "        if word in lexicon.keys():\n",
    "            emotionWords += 1\n",
    "            emotionCount = emotionCount + lexicon[word]\n",
    "        \n",
    "    # Avg over all words\n",
    "    if emotionWords > 0:\n",
    "        emotionCount = emotionCount / emotionWords\n",
    "    \n",
<<<<<<< HEAD
    "    return emotionCount\n",
    "\n",
    "string1 = sampleData[45].get('reviewText')\n",
    "print(getEmotions(simple_preprocess(string1, deacc = True), lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have both a Baltimore Ravens and now a Baltimore Orioles lanyard. I use mine for work to hold my ID card. While most just use the standard rope, I like to support my teams any way I can and look cool at it. The lanyard is a good size for an ID badge holder and very well made. The print on it is very sharp and clear. I would recommend this if you are a die hard Orioles fan that works in an office - it is just really cool to show off.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('anger', 0.06896551724137931),\n",
       " ('anticipation', 0.0),\n",
       " ('disgust', 0.034482758620689655),\n",
       " ('fear', 0.06896551724137931),\n",
       " ('joy', 0.034482758620689655),\n",
       " ('negative', 0.10344827586206896),\n",
       " ('positive', 0.27586206896551724),\n",
       " ('sadness', 0.06896551724137931),\n",
       " ('surprise', 0.0),\n",
       " ('trust', 0.13793103448275862)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = i+1\n",
    "string1 = sampleData[i].get('reviewText')\n",
    "em_vec = getEmotions(simple_preprocess(string1, deacc = True), lexicon)\n",
    "print(string1)\n",
    "list(zip(emotionList, em_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Takes 0.0033037662506103516,Takes 0.0007808208465576172,Takes 0.0003094673156738281,Takes 0.0062711238861083984,Takes 0.000583648681640625,Takes 0.00033926963806152344,Takes 0.0011785030364990234,Takes 0.0018792152404785156,Takes 0.0017588138580322266,Takes 0.4016759395599365,Takes 0.00020933151245117188,Takes 0.0007688999176025391,Takes 0.0011649131774902344,Takes 0.0007798671722412109,Takes 0.0001735687255859375,Takes 0.0012097358703613281,Takes 0.0009903907775878906,Takes 0.0014233589172363281,Takes 0.0008344650268554688,Takes 0.0012199878692626953,Takes 0.0008778572082519531,Takes 0.00012731552124023438,Takes 0.00012350082397460938,Takes 4.352596044540405,Takes 0.6008195877075195,Takes 0.0008301734924316406,Takes 0.00012969970703125,Takes 0.0012807846069335938,Takes 0.0010068416595458984,Takes 1.3344709873199463,"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(30):\n",
    "    ra = randint(0, len(sampleData))\n",
    "    time0 = time.time()\n",
    "    getEmotions(simple_preprocess(sampleData[ra].get('reviewText')), lexicon)\n",
    "    time1 = time.time()\n",
    "    print(f'Takes {time1-time0},',end='')"
=======
    "    return emotionCount"
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 185,
=======
   "execution_count": 39,
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%]\r"
     ]
    }
   ],
   "source": [
    "# Get the sample data\n",
    "num = 10000\n",
    "sampleData = []\n",
    "for i in range(num):\n",
    "    index = randint(0,len(json_dat))\n",
    "    sampleData.append(json_dat[index])\n",
    "\n",
    "# Create a vector for each data point\n",
    "scores = []\n",
    "emotions = []\n",
    "for i in range(len(sampleData)):    \n",
    "    print('[%d%%]\\r' % (100*(i+1)/len(sampleData)), end='')\n",
    "    currJson = sampleData[i]\n",
    "    if(not currJson.get('reviewText')):\n",
    "        continue\n",
    "    # Get score\n",
    "    scores.append(currJson.get('overall'))\n",
    "    # Get summary words and do analysis\n",
<<<<<<< HEAD
    "    words, pos = simple_preprocess(currJson.get('reviewText'), deacc=True)\n",
    "    currEmotions = getEmotions(words, lexicon)\n",
    "    emotions.append(currEmotions)\n",
    "    \n",
    "    print('[%d%%]\\r' % (100*(i+1)/len(sampleData)), end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lbls = np.array(scores) >= 4.5\n",
    "np_emotions = np.array(emotions)"
=======
    "    currEmotions = getEmotions(currJson.get('reviewText'), lexicon)\n",
    "    emotions.append(currEmotions)"
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 191,
=======
   "execution_count": 43,
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
<<<<<<< HEAD
    "clf = LinearSVC()\n",
    "pred_score = cross_val_score(clf, np_emotions, train_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6825   , 0.68875  , 0.685    , 0.68625  , 0.6795995])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45586396599149787"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(emotionList, [np.sum(np_emotions[:,i] > 0)/len(train_lbls) for i in range(0,10)]))\n",
    "np.sum((np_emotions[:,6]>=0.4) == train_lbls)/len(train_lbls)"
=======
    "labels = np.array(scores) >= 4.5\n",
    "np_emotions = np.array(emotions)\n",
    "X_train, X_test, y_train, y_test = train_test_split(np_emotions, labels, test_size=0.2)"
>>>>>>> 7673986edfd8c3d3d62481c9fb6d5a69506b004c
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.677\n",
      "Precision: 0.6786437246963563\n",
      "Recall: 0.9918639053254438\n",
      "F1-score: 0.8058894230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.02      0.04       648\n",
      "        True       0.68      0.99      0.81      1352\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.61      0.51      0.42      2000\n",
      "weighted avg       0.63      0.68      0.56      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Make the classifier\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "# np.random.shuffle(y_train)\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "# Model F1-score\n",
    "print(\"F1-score:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Report\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.604\n",
      "Precision: 0.6718946047678795\n",
      "Recall: 0.7992537313432836\n",
      "F1-score: 0.7300613496932515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.34      0.21      0.26       660\n",
      "        True       0.67      0.80      0.73      1340\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.50      0.50      0.49      2000\n",
      "weighted avg       0.56      0.60      0.57      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=8)\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "# Model F1-score\n",
    "print(\"F1-score:\",metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Report\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
