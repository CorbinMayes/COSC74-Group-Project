{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "# note the differences between this and our text. Review text can be messier. It's not always proper english or proofread\n",
    "tagged_sentences = treebank.tagged_sents()\n",
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fw_extract_features(tagged_sentence, index):\n",
    "    token, tag = tagged_sentence[index]\n",
    "    prev_token = \"\"\n",
    "    prev_tag = \"\"\n",
    "    if index > 0:\n",
    "        prev_token, prev_tag = tagged_sentence[index - 1]\n",
    "            \n",
    "    is_number = False\n",
    "    try:\n",
    "        if float(token):\n",
    "            is_number = True\n",
    "    except:\n",
    "        pass\n",
    "    features_dict = {\"token\": token\n",
    "        , \"lower_cased_token\": token.lower()\n",
    "        , \"prev_token\": prev_token\n",
    "        , \"prev_tag\": prev_tag\n",
    "        , \"suffix1\": token[-1]\n",
    "        , \"suffix2\": token[-2:]\n",
    "        , \"suffix3\": token[-3:]\n",
    "        , \"is_capitalized\": token.upper() == token\n",
    "        , \"is_number\": is_number}\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': '61',\n",
       " 'lower_cased_token': '61',\n",
       " 'prev_token': ',',\n",
       " 'prev_tag': ',',\n",
       " 'suffix1': '1',\n",
       " 'suffix2': '61',\n",
       " 'suffix3': '61',\n",
       " 'is_capitalized': True,\n",
       " 'is_number': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw_extract_features(tagged_sentences[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "X_features = []\n",
    "for sentence in tagged_sentences:\n",
    "    for k in range(len(sentence)):\n",
    "        X_features.append(fw_extract_features(sentence, k))\n",
    "\n",
    "vectoriser = DictVectorizer(sparse=False)\n",
    "X = vectoriser.fit_transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for sentence in tagged_sentences:\n",
    "    for k in range(len(sentence)):\n",
    "        Y.append(sentence[k][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603.178388595581\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import time\n",
    "\n",
    "t0=time.time()\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X, Y)\n",
    "t1=time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pos_tagger.clf',mode='wb') as f:\n",
    "    pickle.dump(clf,f)\n",
    "\n",
    "with open('pos_tagger.vec',mode='wb') as f:\n",
    "    pickle.dump(vectoriser,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/bope9760/.conda/envs/mlclass/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526.7728765010834\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import tree\n",
    "\n",
    "t0 = time.time()\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "scores = cross_val_score(clf, X, Y, cv=5, n_jobs=1)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91189909, 0.90812019, 0.90856717, 0.91666253, 0.91894711])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
